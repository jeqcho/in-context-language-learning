{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook clarifies that the HMM internal emission probabilites favour \"also\" over \" \"\n",
    "\n",
    "We will go through each hidden state in the HMM and get the \"also\" token emission probability, as well as the \" \" token emission probability. Then we will plot a histogram of the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tokenizer_lib\n",
    "from hmmlearn import hmm\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the hmm\n",
    "model_name = \"600-word-hmm-300.pkl\"\n",
    "fname = f\"/n/holyscratch01/sham_lab/summer_2024/models/{model_name}\"\n",
    "\n",
    "with open(fname, \"rb\") as f:\n",
    "    hmm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 583)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the shape of the HMM is 300 hidden states and 600 emissions\n",
    "hmm.emissionprob_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a problem. Since the shape is (300, 583) instead of (300, 600), it could be the case that the token id for \" \" no longer means what it should be.\n",
    "\n",
    "I will now run an experiment to see if given tokens (0,1,100,101), a 2-hidden state HMM will collapse the dimensions from (2,100) to (2, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider a simple model with two hidden states\n",
    "# the first hidden state is a fair coin emitting 0 and 1 with equal chance\n",
    "# the second hidden state gives out p(100)=0.9 and p(101)=0.1\n",
    "# both states are highly stable, with probability of switching 0.1 equally\n",
    "\n",
    "\n",
    "def generate_sample(length: int):\n",
    "    \"\"\"\n",
    "    Returns hidden_states and emissions given the model specs above\n",
    "    \"\"\"\n",
    "    # hidden_states are 0 or 1\n",
    "    # initial hidden state can be either\n",
    "    hidden_states = [int(random.random() < 0.5)]\n",
    "    while len(hidden_states) < length:\n",
    "        switch_flag = int(random.random() < 0.1)\n",
    "        if switch_flag:\n",
    "            next_hidden_state = 1 - hidden_states[-1]\n",
    "        else:\n",
    "            next_hidden_state = hidden_states[-1]\n",
    "        hidden_states.append(next_hidden_state)\n",
    "    emissions = []\n",
    "    for hidden_state in hidden_states:\n",
    "        if hidden_state:\n",
    "            # 0 or 1 equal chance\n",
    "            emission = int(random.random() < 0.5)\n",
    "        else:\n",
    "            # 101 with 10% and 100 with 90%\n",
    "            emission = 101 if random.random() < 0.1 else 100\n",
    "        # wrap it with [] since the package supports multi-dimensional emissions\n",
    "        emissions.append([emission])\n",
    "    return hidden_states, emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3251.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# as required by the package, the data will have all sequences concatenated together\n",
    "sample_length = 500\n",
    "num_samples = 10000\n",
    "samples = []\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    samples += generate_sample(sample_length)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the HMM will tell the sequences apart by using the lengths array\n",
    "lengths = [sample_length] * num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the HMM\n",
    "n_components = 2\n",
    "model = hmm.CategoricalHMM(n_components=n_components).fit(samples, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 102)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the emission shape\n",
    "model.emissionprob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00117238, 0.00136042, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.89768888, 0.09977832])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emissionprob_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.97983409e-01, 4.98511841e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.12691508e-03, 3.77834812e-04])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emissionprob_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9043841 , 0.0956159 ],\n",
       "       [0.09544971, 0.90455029]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transmat_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HMM is a successful fit of the model.\n",
    "\n",
    "The question is also answered: the model keeps the number of features as 102.\n",
    "\n",
    "This hints towards that the HMM shape is (300, 583) simply because that the largest token id seen is 582.\n",
    "\n",
    "Next steps:\n",
    "- Plot the histogram of emission probabilities for the space token and also token\n",
    "- Inspect the hidden states that have high emission probabilities for the space token\n",
    "    - e.g. look at their transition probabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
