#%%
import torch
import numpy as np
from .markov_chain_generator import generate_markov_chain
from random import choices
from typing import Tuple


def generate_hmm_sequence(
    num_symbols: int, num_hidden_states: int, seq_len: int
) -> Tuple[torch.Tensor, np.ndarray, torch.Tensor]:
    """
    Generates a sequence of observations from a Hidden Markov Model (HMM) with a given number of symbols, hidden states, and sequence length.
    The HMM is generated by first generating a Markov chain as the hidden states, and then generating an emission matrix.
    The hidden states are then replaced with emissions to generate the observed sequence.
    :param num_symbols: the number of symbols in the sequence
    :param num_hidden_states: the number of hidden states in the HMM
    :param seq_len: the length of the sequence
    :return: the observed sequence, the emission matrix, the hidden sequence
    """
    # generate a Markov chain as the hidden states
    hidden_sequence, transition_matrix, chosen_symbols = generate_markov_chain(
        num_symbols=num_hidden_states, seq_len=seq_len, deterministic=False, doubly_stochastic=False
    )

    # generate the emission matrix
    emission_matrix = np.random.dirichlet(np.ones(num_symbols), size=(num_hidden_states,))

    # replace the hidden states with the emissions
    observed_sequence = torch.tensor(
        [np.random.choice(num_symbols, p=emission_matrix[state]) for state in hidden_sequence], dtype=torch.int32
    )

    # for evaluation we effectively need the distirbution of emissions of the next state
    # this is conveniently transition_matrix @ emission_matrix

    next_emission_matrix = transition_matrix @ emission_matrix

    return observed_sequence, next_emission_matrix, hidden_sequence

# %%
